\subsection*{الف}

در مدل‌سازی آماری و یادگیری ماشین،
\lr{overfitting}
و
\lr{underfitting}
دو مشکل مهم هستند.


\lr{Overfitting}
اتفاق می‌افتد وقتی مدلی داده‌های آموزشی را خیلی خوب یاد می‌گیرد تا جایی که دقت آن بر روی داده‌های جدید یا تست کاهش می‌یابد. به عبارت دیگر، مدل تمامی جزئیات و سر و صداهای موجود در داده‌های آموزشی را یاد می‌گیرد که ممکن است در داده‌های جدید یا تست موجود نباشد. این باعث می‌شود مدل قادر به تعمیم داده‌های جدید نباشد.

\lr{Underfitting}
اتفاق می‌افتد وقتی مدل نمی‌تواند الگوهای موجود در داده‌ها را بخوبی بیاموزد. این اغلب به دلیل سادگی بیش از حد مدل (به عنوان مثال، یک مدل خطی برای داده‌های غیرخطی) یا نبود داده‌های کافی برای یادگیری الگوهای پیچیده اتفاق می‌افتد. 
\lr{Underfitting}
باعث می‌شود مدل نتواند به خوبی بر روی هم داده‌های آموزش و هم داده‌های تست عمل کند.

برای مثال، فرض کنید که شما می‌خواهید یک مدل یادگیری ماشین را برای پیش‌بینی قیمت خانه بر اساس متراژ آن آموزش دهید. اگر مدل شما
\lr{overfitting}
کند، ممکن است از یک مدل پیچیده بیش از حد استفاده کند که هر نوسان کوچک در قیمت خانه‌های آموزشی را یاد می‌گیرد، اما بر روی داده‌های تست خوب عمل نمی‌کند. اگر مدل شما
\lr{underfitting}
کند، ممکن است از یک مدل خیلی ساده استفاده کند (مثلا یک خط ساده) که نمی‌تواند تغییرات قیمت خانه را بر اساس متراژ بخوبی بیاموزد.

مفهوم 
\lr{overfitting}
در سمت راست نمودار و جایی که فاصله‌ی
\lr{error}
ها افزایش می‌یابد، قابل مشاهده است.

مفهوم 
\lr{underfitting}
در سمت چپ بالای نمودار قابل مشاهده است.

\subsection*{ب}

زمانی که پیجیدگی مدل کم است، خطای 
\lr{Validation Set}
و
\lr{Train Set}
هر دو زیاد است و اصلا از نقاط درست نمی‌گذرند.

زمانی که پیجیدگی مدل بیشتر می‌شود،
\lr{overfitting}
رخ می‌دهد و خطای
\lr{Train Set}
از خطای
\lr{Validation Set}
کمتر است و در نتیجه نمودار دوم شبیه‌ترین نمودار به خطای مدل بر روی داده‌های تست است.